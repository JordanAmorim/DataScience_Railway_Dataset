{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from os import listdir\n",
    "from os import mkdir\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicando as pastas de fonte dos arquivos originais da região 5 e destino dos arquivos chaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LRV4306_accelerometer_data', 'LRV4306_accelerometer_data_teste', 'LRV4306_gps_data', 'LRV4306_gps_data_teste', 'LRV4313_accelerometer_data', 'LRV4313_gps_data']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Pasta de origem dos dados e pasta de destino para os dados trabalhados\"\"\"\n",
    "path_sources = r'C:\\Users\\vinic\\python_projects\\monitoracao_project\\dados'\n",
    "path_destiny = r'C:\\Users\\vinic\\python_projects\\monitoracao_project\\dados_parquet'\n",
    "\n",
    "folders = listdir(path_sources) # Lembrar de tirar o [0] quando for rodar tudo\n",
    "#folders = [folders[1]] # teste com uma pasta só\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código para criação do dataframe das chaves de acesso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(folders)):\n",
    "\n",
    "    if 'accel' in folders[i]:\n",
    "        Chaves = pd.DataFrame(columns=['Data', 'N Passagens', 'Direcao', 'Sensor', 'Chave'])\n",
    "\n",
    "    elif 'gps' in folders[i]:\n",
    "        Chaves = pd.DataFrame(columns=['Data', 'N Passagens', 'Direcao', 'Chave'])\n",
    "    \n",
    "    name = folders[i]\n",
    "\n",
    "    path_sour = path_sources+'\\\\'+folders[i] # entra na pasta com arquivos\n",
    "    path_dest = path_destiny+'\\\\'+folders[i] # entra na pasta onde os arquivos serão salvos\n",
    "\n",
    "    try:\n",
    "        mkdir(path_dest) # cria pastas de acordo com o nome da pasta de origem\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    files = listdir(path_sour) # Carrega os nomes dos arquivos dentro da pasta de origem\n",
    "\n",
    "        # Quantidade de linhas no arquivo?\n",
    "\n",
    "\n",
    "    for n in range(len(files)):\n",
    "    \n",
    "        j = files[n]\n",
    "\n",
    "        props = j.split('_')\n",
    "        props[-1] = props[-1][0]\n",
    "\n",
    "        l = path_sour+'\\\\'+j\n",
    "        m = path_dest+'\\\\'+j\n",
    "\n",
    "        if 'accel' in folders[i]:\n",
    "            #{file#}_{date}_{root index}_{daily passing#}_{region#}_{running direction}_{sensor channel}.mat\n",
    "            df_temp = pd.DataFrame({'Data':[props[1]], 'N Passagens':[props[3]], 'Direcao':[props[5]], 'Sensor':[props[6]], 'Chave': l})\n",
    "            Chaves = pd.concat([Chaves, df_temp], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "        elif 'gps' in folders[i]:\n",
    "\n",
    "            df_temp = pd.DataFrame({'Data':[props[1]], 'N Passagens':[props[3]], 'Direcao':[props[5]], 'Chave':l})\n",
    "            Chaves = pd.concat([Chaves, df_temp], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "    Chaves.to_parquet(path_dest+'\\\\'+name+'_key', engine = 'pyarrow', compression= 'brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento de arquivos específicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'20150618',\n",
       " '20150625',\n",
       " '20150818',\n",
       " '20150924',\n",
       " '20151022',\n",
       " '20151029',\n",
       " '20151105',\n",
       " '20151203',\n",
       " '20151210',\n",
       " '20160114',\n",
       " '20160128',\n",
       " '20160228',\n",
       " '20160407',\n",
       " '20160414',\n",
       " '20160421',\n",
       " '20160505',\n",
       " '20160519'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chaves\n",
    "datas = set(Chaves.loc[:,'Data'])\n",
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [] # Guarda qualquer arquivo que falhou em ser carregado\n",
    "linha = 0\n",
    "for i in range(len(folders)):\n",
    "\n",
    "    path_sour = path_destiny+'\\\\'+folders[i] # entra na pasta com as chaves\n",
    "    \n",
    "    files = listdir(path_sour) # Carrega os nomes dos arquivos dentro da pasta de origem\n",
    "\n",
    "    for n in range(len(files)):\n",
    "        if 'key' in files[i]:\n",
    "\n",
    "            l = path_sour+'\\\\'+files[i]\n",
    "            \n",
    "            Chaves = pd.read_parquet(l)\n",
    "            \n",
    "            datas = set(Chaves.loc[:,'Data'])\n",
    "            n_passagens = set(Chaves.loc[:,'N Passagens'])\n",
    "            direcoes = set(Chaves.loc[:,'Direcao'])\n",
    "\n",
    "            if 'accel' in files[n]:\n",
    "                sensores = set(Chaves.loc[:,'Sensor'])\n",
    "            elif 'gps' in files[n]:\n",
    "                sensores = None\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste sensor 1 dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste de qualidade dos dados\n",
      "--------------------------------\n",
      "Elementos faltantes na coluna Data?\n",
      "{False}\n",
      "Tamanho na coluna Data\n",
      "3469\n",
      "-----------------------------------\n",
      "Elementos faltantes na coluna N Passagens?\n",
      "{False}\n",
      "Tamanho na coluna N Passagens\n",
      "3469\n",
      "-----------------------------------\n",
      "Elementos faltantes na coluna Direcao?\n",
      "{False}\n",
      "Tamanho na coluna Direcao\n",
      "3469\n",
      "-----------------------------------\n",
      "Elementos faltantes na coluna Sensor?\n",
      "{False}\n",
      "Tamanho na coluna Sensor\n",
      "3469\n",
      "-----------------------------------\n",
      "Elementos faltantes na coluna Chave?\n",
      "{False}\n",
      "Tamanho na coluna Chave\n",
      "3469\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# tratar dados que são None\n",
    "print('Teste de qualidade dos dados')\n",
    "print('--------------------------------')\n",
    "for i in Chaves.keys():\n",
    "    print(f'Elementos faltantes na coluna {i}?')\n",
    "    print(set(Chaves.loc[:, 'Sensor'] == None))\n",
    "    print(f'Tamanho na coluna {i}')\n",
    "    print(len(Chaves.loc[:, 'Sensor']))\n",
    "    print('-----------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "735fd90a47749e3d8aef9bbc1d196bfbcc60e5c47746d2d32e6f03ac88616da3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
